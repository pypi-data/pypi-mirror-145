{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52f50b0a",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/sparks-baird/AxForChemistry/blob/main/tutorials/multi_objective_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# Generate Sobol and multi-objective SAASBO Bayesian candidates for wetlab experiments\n",
    "\n",
    "The first step is to generate a list of Sobol candidates, to be synthesized in a wetlab\n",
    "environment or calculated if a simulation, etc. Once these candidates have been added\n",
    "as a new .csv file (default is \"post-sobol.csv\") following the same format as the\n",
    "training data, the second step will call `form.bayes_opt()`. At this point, it will suggest a batch of next best\n",
    "experiments based on Pareto front-aware multi-objective optimization (MOO) to run for\n",
    "a single adaptive design iteration. Note that the CSV file that gets loaded should be\n",
    "stripped of any extra columns, otherwise these will be treated as search parameters. For\n",
    "example, if you give it a CSV with multiple objectives and run a single-objective\n",
    "optimization, the additional objectives will be erroneously considered as part of the\n",
    "parameter search space.\n",
    "\n",
    "For more information, see https://ax.dev/tutorials/saasbo_nehvi.html\n",
    "\n",
    "Additional batches can then be generated. The setup of this tutorial assumes that there is some time between\n",
    "when the experiments are suggested and when they are completed, and that experiments are\n",
    "carried out \"offline\" (meaning this is not a closed-loop optimization process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f47ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install axforchemistry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb25889",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714bda58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from axforchemistry.axforchemistry_ import FormulationOptimization\n",
    "from ax.service.utils.instantiation import ObjectiveProperties\n",
    "from axforchemistry.utils.data import make_compositional_regression\n",
    "from axforchemistry.utils.plotting import cv_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7fb9e0",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "To perform multi-objective optimization (MOO), specify the names of the objectives based\n",
    "on the columns in the CSV file(s) of interest and whether the objective should be\n",
    "minimized or maximized. `threshold == None` means to infer a threshold that the model\n",
    "uses to help focus the search to a more useful range for the objective values. This\n",
    "threshold acts as a soft constraint, and is set as a scalar value. For example, by\n",
    "specifying `threshold=200` for the `\"Compressive Strength (MPa)\"` objective, where\n",
    "greater is better (`minimize=False`), candidates that are likely to perform worse than this threshold are\n",
    "less likely to be suggested as next experiments. In other words, this is a place where\n",
    "you can bake-in domain knowledge to help the model decide what is useful or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c357dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressive_key = \"Compressive Strength (MPa)\"\n",
    "flexural_key = \"Flexural Strength (MPa)\"\n",
    "vickers_key = \"Vickers Hardness\"\n",
    "shrinkage_key = \"Shrinkage (%)\"\n",
    "moo_objectives = {\n",
    "    compressive_key: ObjectiveProperties(minimize=False, threshold=None),\n",
    "    flexural_key: ObjectiveProperties(minimize=False, threshold=None),\n",
    "    vickers_key: ObjectiveProperties(minimize=False, threshold=None),\n",
    "    shrinkage_key: ObjectiveProperties(minimize=True, threshold=None),\n",
    "}\n",
    "\n",
    "data_dir = \"data\"\n",
    "train_fname = \"train-moo-fake.csv\"\n",
    "post_sobol_fname = \"post-sobol-moo-fake.csv\"\n",
    "\n",
    "figdir = path.join(\"figures\", \"moo\")\n",
    "\n",
    "# trim the data down to the first 10 datapoints so it runs very fast (dummy run)\n",
    "trim = False\n",
    "if trim:\n",
    "    df = pd.read_csv(path.join(data_dir, post_sobol_fname))\n",
    "    df = df.head(10)\n",
    "    post_sobol_fname = \"post-sobol-moo-fake-dummy.csv\"\n",
    "    df.to_csv(path.join(data_dir, post_sobol_fname), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06aaf19",
   "metadata": {},
   "source": [
    "### Generate dummy data\n",
    "\n",
    "The following is generated from a linear model and then the inputs are reworked to conform to our compositional constraint, such that each component is positive and `component_0 + component_1 + ... + component_n == 1.0`. We reparameterize this to `component_0 + component_1 + ... + component_{n-1} <= 1.0` to remove a degenerate dimension of the search and thereby increase the search efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "n_features = 10\n",
    "n_targets = len(moo_objectives)\n",
    "targ_columns = [compressive_key, flexural_key, vickers_key, shrinkage_key]\n",
    "\n",
    "df = make_compositional_regression(\n",
    "    data_dir, train_fname, targ_columns, n_samples, n_features, n_targets\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ef8059",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "The optimization takes place with the FormulationOptimization class, which refers to\n",
    "optimization of a formulation of components (i.e. `component_1 + component_2 +\n",
    "component_3 + ... + component_n`) such that the sum of the fractional contributions of\n",
    "all the components is equal to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f064f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: allow passing DataFrames directly\n",
    "form = FormulationOptimization(\n",
    "    train_max_val=1.0,  # i.e. i.e. x_1 + x_2 + x_3 + ... + x_{n-1} <= train_max_val\n",
    "    sobol_max_val=0.25,  # i.e. x_1 + x_2 + x_3 + ... + x_{n-1} <= sobol_max_val\n",
    "    sobol_min_val=0.15,  # i.e. x_1 + x_2 + x_3 + ... + x_{n-1} >= sobol_min_val\n",
    "    bayes_max_val=None,  # default to Sobol equivalent\n",
    "    bayes_min_val=None,  # default to Sobol equivalent\n",
    "    seed=12345,\n",
    "    n_bayes_batch=5,\n",
    "    n_sobol=10,  # None --> 2*num_parameters\n",
    "    num_samples=256,  # set to 256+ for real run (lower if OOM, e.g. 64), 16 for dummy run\n",
    "    warmup_steps=512,  # set to 512+ for real run (lower if OOM, e.g. 128), 32 for dummy run\n",
    "    exp_name=\"moo-example\",\n",
    "    moo_objectives=moo_objectives,\n",
    "    exp_dir=path.join(\"experiments\", \"moo\"),\n",
    "    save_dir=path.join(\"results\", \"moo\"),\n",
    "    data_dir=data_dir,\n",
    "    train_fname=train_fname,\n",
    "    post_sobol_fname=post_sobol_fname,  # same format as `train_fname` + train data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b7608b",
   "metadata": {},
   "source": [
    "## Sobol candidates\n",
    "\n",
    "First, we generate the suggested (pseudo-random) Sobol experiments to provide an initial\n",
    "scaffolding for the initial model fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6542e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"generating Sobol candidates and saving to .csv\")\n",
    "sobol_df, ax_sobol = form.train_and_sobol()\n",
    "model = form.pre_sobol_model\n",
    "sobol_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554de493",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "Now, we take a look at the cross-validation (CV) results for the SAASBO model using\n",
    "the existing training data that was supplied to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f12025d",
   "metadata": {},
   "outputs": [],
   "source": [
    "figdir2 = path.join(figdir, \"pre-sobol\")\n",
    "cv_results, fig, tile_fig = cv_plot(\n",
    "    model,\n",
    "    figdir=figdir2,\n",
    "    fname=\"moo-cv\",\n",
    "    matplotlibify_kwargs=dict(height_inches=7.0, width_inches=7.0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e9ee2f",
   "metadata": {},
   "source": [
    "## Bayesian candidates\n",
    "\n",
    "### First iteration\n",
    "After completing the Sobol experiments (e.g. via wetlab synthesis and characterization)\n",
    "and recording the measured objectives along with all of the available training data\n",
    "within the `post_sobol_fname` file (e.g. `post-sobol-moo-fake.csv`), run the following cell\n",
    "to generate the first batch of SAASBO Bayesian optimization candidates. The process is\n",
    "then repeated: perform the suggested (real-world) experiments and run the script again\n",
    "to get another batch of suggested candidates. This is meant to be an offline, manual\n",
    "process geared towards manual experimental wetlab synthesis and characterization, though\n",
    "more automated options exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"generating Bayes candidates and saving to .csv\")\n",
    "bayes_df, ax_bayes = form.bayes_opt()\n",
    "model = ax_bayes.generation_strategy.model\n",
    "bayes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa1ffb3",
   "metadata": {},
   "source": [
    "At this point, you will run the SAASBO suggested experiments. Note that you are free\n",
    "to run all of them, downselect, or modify the values of individual experiments, but if\n",
    "you add or remove any parameters, these need to be represented for all variables. In the\n",
    "case of a formulation where you decide to include a new component (e.g. a chemical that\n",
    "you haven't used before), this is easy; simply add a column with `0.0` everywhere except\n",
    "where you used the new chemical.\n",
    "\n",
    "### Plotting\n",
    "\n",
    "We can take a look at the cross-validation (CV) results for the SAASBO model using\n",
    "whatever fully recorded data was made available to the model (i.e. existing training\n",
    "data and Sobol data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fce8f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "figdir2 = path.join(figdir, \"post-sobol\")\n",
    "cv_results, fig, tile_fig = cv_plot(\n",
    "    model,\n",
    "    figdir=figdir,\n",
    "    fname=\"moo-cv\",\n",
    "    matplotlibify_kwargs=dict(height_inches=7.0, width_inches=7.0),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb2025",
   "metadata": {},
   "source": [
    "### Second iteration\n",
    "Once you have finished running the experiments and have\n",
    "updated the `post_sobol_fname` file (e.g. `post-sobol-moo-fake.csv`), then you can run\n",
    "the second iteration of SAASBO suggested experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557dc0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure that `post_sobol_fname` file was updated with the new information.\n",
    "print(\"generating Bayes candidates and saving to .csv\")\n",
    "bayes_df, ax_bayes = form.bayes_opt()\n",
    "model = ax_bayes.generation_strategy.model\n",
    "bayes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0600512",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "We can take a look at the cross-validation (CV) results for the SAASBO model after\n",
    "the first iteration using whatever fully recorded data was made available to the model\n",
    "(i.e. existing training data, Sobol data, and the first Bayesian batch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21c418d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "figdir2 = path.join(figdir, \"bayes-0\")\n",
    "cv_results, fig, tile_fig = cv_plot(\n",
    "    model,\n",
    "    figdir=figdir,\n",
    "    fname=\"moo-cv\",\n",
    "    matplotlibify_kwargs=dict(height_inches=7.0, width_inches=7.0),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
